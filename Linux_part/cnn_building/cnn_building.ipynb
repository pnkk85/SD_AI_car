{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../myCNN')\n",
    "import models, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is copied from NVIDIA website\n",
    "# Configure GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "DATA_DIRECTORY = 'DATA/dataset_home_twolines_1'\n",
    "MODEL_DIRECTORY = 'saved_models'\n",
    "MODEL_SHORT_DESCRIPTION = 'at_home_twolines'\n",
    "IMG_WIDTH = datasets.get_image_width()\n",
    "IMG_HEIGHT = datasets.get_image_height()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "print('Importing data set ...', end=' ')\n",
    "directory = datasets.get_directory(DATA_DIRECTORY)\n",
    "image_paths = datasets.get_image_paths(directory)\n",
    "images = datasets.load_images_to_array(image_paths)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale images to the range [0-1]\n",
    "images = images / 255.0\n",
    "images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load steer and throttle dataset\n",
    "steer_throttle = datasets.load_steer_throttle_to_array(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test sets\n",
    "(trainValX, testValX, trainImgX, testImgX) = train_test_split(steer_throttle, images, test_size=0.25, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale steer an throttle to the range [0-1]\n",
    "max_steer = trainValX[:, 0].max()\n",
    "min_steer = trainValX[:, 0].min()\n",
    "max_throttle = trainValX[:, 1].max()\n",
    "min_throttle = trainValX[:, 1].min()\n",
    "trainY = [1 / (max_steer - min_steer) * (trainValX[:, 0] - min_steer),\n",
    "          1 / (max_throttle - min_throttle) * (trainValX[:, 1] - min_throttle)]  # obtained from y = ax + b ...\n",
    "testY = [1 / (max_steer - min_steer) * (testValX[:, 0] - min_steer),\n",
    "         1 / (max_throttle - min_throttle) * (testValX[:, 1] - min_throttle)]  # obtained from y = ax + b ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print min and max values used for dataset scaling \n",
    "print('MAX steer: %d' % max_steer)\n",
    "print('MIN steer: %d' % min_steer)\n",
    "print('MAX throttle %d' % max_throttle)\n",
    "print('MIN throttle %d' % min_throttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "trainY = np.array(trainY).T\n",
    "testY = np.array(testY).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = models.create_cnn(IMG_WIDTH, IMG_HEIGHT)\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "# print model summary\n",
    "print('Model summary:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(trainImgX, trainY, validation_data=(testImgX, testY), epochs=4, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model name in proper format\n",
    "act_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_name_h5 = datasets.get_model_name(act_time, max_steer, min_steer, max_throttle, min_throttle, MODEL_SHORT_DESCRIPTION,'h5')\n",
    "\n",
    "# save h5 model\n",
    "model.save(os.path.join(MODEL_DIRECTORY, model_name_h5))\n",
    "\n",
    "print('Model saved under: ')\n",
    "print('../',end='')\n",
    "print(os.path.join(MODEL_DIRECTORY, model_name_h5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(os.path.join(MODEL_DIRECTORY, model_name_h5))\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantised Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model name in proper format\n",
    "model_name_tflite = datasets.get_model_name(act_time, max_steer, min_steer, max_throttle, min_throttle, MODEL_SHORT_DESCRIPTION, 'tflite')\n",
    "\n",
    "# save tflite model\n",
    "file = open(os.path.join(MODEL_DIRECTORY, model_name_tflite), 'wb')\n",
    "file.write(quant_model)\n",
    "\n",
    "print('Quantised model saved under: ')\n",
    "print('../',end='')\n",
    "print(os.path.join(MODEL_DIRECTORY, model_name_tflite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
